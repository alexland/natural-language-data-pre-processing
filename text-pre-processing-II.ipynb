{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imports, configs, etc.\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import re\n",
      "from copy import deepcopy\n",
      "import collections as CL\n",
      "import itertools as IT\n",
      "import numpy as NP\n",
      "from scipy import linalg as LA\n",
      "from sklearn import svm as SVM\n",
      "from IPython.display import display"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sympy.interactive import printing\n",
      "import sympy as SYM\n",
      "from sympy import Matrix as MAT\n",
      "from sympy.mpmath import *\n",
      "printing.init_printing()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.external import mathjax; mathjax.install_mathjax()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "offline MathJax apparently already installed\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as PLT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imports, configs, etc.\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import re\n",
      "import csv as CSV\n",
      "from copy import deepcopy\n",
      "import collections as CL\n",
      "import itertools as IT\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "import numpy as NP\n",
      "from scipy import linalg as LA\n",
      "from IPython.display import display\n",
      "from sympy.interactive import printing\n",
      "import sympy as SYM\n",
      "from sympy import Matrix as MAT\n",
      "from sympy.mpmath import *\n",
      "printing.init_printing()\n",
      "\n",
      "from IPython.external import mathjax; mathjax.install_mathjax()\n",
      "\n",
      "%matplotlib inline\n",
      "from matplotlib import pyplot as PLT\n",
      "from matplotlib import cm as CM\n",
      "from mpl_toolkits import axes_grid1 as AG\n",
      "from mpl_toolkits.mplot3d import Axes3D as AX\n",
      "\n",
      "NP.set_printoptions(precision=3, suppress=True)\n",
      "PLT.rcParams['figure.figsize'] = (11.0, 7.5)\n",
      "\n",
      "my_font_config = {'family' : 'sans-serif',\n",
      "        'color'  : '#2A52BE',\n",
      "        'weight' : 'normal',\n",
      "        'size'   : 14,\n",
      "        }\n",
      "\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "DATA_DIR = \"~/data\"\n",
      "DATA_DIR = os.path.expanduser(DATA_DIR)\n",
      "PROJ_DIR = os.path.join(DATA_DIR, \"mobile-apps\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "offline MathJax apparently already installed\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_file = os.path.join(PROJ_DIR, \"class_labels.txt\")\n",
      "data_file = os.path.join(PROJ_DIR, \"data.txt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SW = stopwords.words('english')\n",
      "\n",
      "import re\n",
      "ptn_nwc = \"[!#$%&'*+/=?`{|}~^.-]\"\n",
      "ptn_nwc_obj = re.compile(ptn_nwc, re.MULTILINE)\n",
      "\n",
      "# open the two files\n",
      "# read them in\n",
      "# normalize: lower case the text \n",
      "# remove end-of-line whitespace\n",
      "# remove punctuation\n",
      "# tokenize the lines\n",
      "\n",
      "with open(data_file, mode='r', encoding='utf-8') as fh:\n",
      "    d = ( ptn_nwc_obj.sub('', line.strip().lower()).split() \n",
      "         for line in fh.readlines() )\n",
      "\n",
      "with open(labels_file, mode='r', encoding='utf-8') as fh:\n",
      "    l = [ int(line.strip()) for line in fh.readlines() ]    \n",
      "    \n",
      "# remove 'stop words' (using the NLTK set) &\n",
      "# remove words comprised of three letters or fewer\n",
      "d = (filter(lambda v: (v not in SW) & (len(v) > 4), line) for line in d)\n",
      "d = deepcopy([list(line) for line in d])\n",
      "\n",
      "# remove frequent terms common to all mobile apps:\n",
      "# (generated by scraping the app summaries \n",
      "# from AppData's 1000 most popular mobiles apps)\n",
      "DOMAIN_STOP_WORDS = ['android', 'free', 'iphone', 'twitter', 'download', \n",
      "                      'feature', 'features', 'applications', 'application', \n",
      "                      'user', 'users', 'version', 'versions', 'facebook', \n",
      "                      'phone', 'available', 'using', 'information', 'provide',\n",
      "                      'include', 'every', 'device', 'mobile', 'friend',\n",
      "                      'different', 'please', 'simple', 'email', 'share', 'follow',\n",
      "                      'great', 'screen', 'provide', 'acces', 'first', 'sound', 'video',]\n",
      "                         \n",
      "d = (filter(lambda v: (v not in DOMAIN_STOP_WORDS), line) for line in d)\n",
      "\n",
      "# normalize: simple word stemming\n",
      "def stem(word):\n",
      "    if word.endswith('s'):\n",
      "        return word[:-1]\n",
      "    else:\n",
      "        return word\n",
      "\n",
      "d = (list(map(stem, line)) for line in d)\n",
      "\n",
      "d1 = deepcopy([list(line) for line in d])\n",
      "\n",
      "lx = NP.array([len(line) for line in d1])\n",
      "\n",
      "# ~ 75 lines have 10 words or fewer\n",
      "idx = lx > 10\n",
      "sum(-idx)\n",
      "\n",
      "# so (temporarily) filter lines having 10 words or fewer &\n",
      "# filter their corresponding class labels\n",
      "\n",
      "idx = idx.tolist()\n",
      "d = IT.compress(d1, idx)\n",
      "l = IT.compress(l, idx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# partition the data & class labels into class I and class 0\n",
      "\n",
      "d = deepcopy([list(line) for line in d])\n",
      "l = deepcopy([line for line in l])\n",
      "\n",
      "assert len(d) == len(l)\n",
      "\n",
      "# shuffle both containers\n",
      "idx = NP.random.permutation(NP.arange(len(d)))\n",
      "d, l = NP.array(d), NP.array(l, dtype='int8')\n",
      "d, l = d[idx], l[idx]\n",
      "\n",
      "L = NP.array(l)\n",
      "    \n",
      "idx1 = l==1\n",
      "idx0 = l==0\n",
      "d1, l1 = d[idx1], l[idx1]\n",
      "d0, l0 = d[idx0], l[idx0] \n",
      "\n",
      "assert d1.size == l1.size\n",
      "assert d0.size == l0.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# any differences in the size of the raw data instances by class?\n",
      "\n",
      "ld1 = NP.array([ len(line) for line in d1 ])\n",
      "ld0 = NP.array([ len(line) for line in d0 ])\n",
      "\n",
      "print(\"mean word length of class 1 instances: {0:.2f}\".format(ld1.mean()))\n",
      "print(\"mean word length of class 0 instances: {0:.2f}\".format(ld0.mean()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mean word length of class 1 instances: 84.53\n",
        "mean word length of class 0 instances: 81.87\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# look at the data by class\n",
      "\n",
      "words_1 = [ word for line in d1 for word in line ]\n",
      "words_0 = [ word for line in d0 for word in line ]\n",
      "words_01 = [ word for line in d for word in line ]\n",
      "\n",
      "import collections as CL\n",
      "\n",
      "def term_counter(word_bag):\n",
      "    \"\"\"\n",
      "    returns: dict whose keys are terms and values are absolute counts\n",
      "        for that term\n",
      "    pass in: python list of terms\n",
      "    \"\"\"\n",
      "    term_counter = CL.defaultdict(int)\n",
      "    for term in word_bag:\n",
      "        term_counter[term] += 1\n",
      "    return term_counter\n",
      "\n",
      "term_count_1 = term_counter(words_1)\n",
      "term_count_0 = term_counter(words_0)\n",
      "term_count_all = term_counter(words_01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_count_1_sorted = sorted(zip(term_count_1.values(), term_count_1.keys()), reverse=True)\n",
      "term_count_0_sorted = sorted(zip(term_count_0.values(), term_count_0.keys()), reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v1 = [t[1] for t in term_count_1_sorted[:100]]\n",
      "v0 = [t[1] for t in term_count_0_sorted[:100]]\n",
      "v1.extend(v0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_feature_vector(data, feature_vector):\n",
      "    \"\"\"\n",
      "    returns: a structured 2D data array comprised of in which\n",
      "        each column encodes one discrete feature; each row\n",
      "        represents one data instance\n",
      "    pass in: \n",
      "        (i) the data: a nested list in which each list is one data instance,\n",
      "            or 'bag of words';\n",
      "        (ii) a template feature vector: a list of terms, comprising a subset\n",
      "            of the population whose frequency will be counted to to supply\n",
      "            the values comprising each feature vector \n",
      "    this fn transforms a sequence of word bags (each bag is a python list)\n",
      "        into a structured 1D NumPy array of features\n",
      "    \"\"\"\n",
      "    import numpy as NP\n",
      "    import collections as CL\n",
      "    from copy import deepcopy\n",
      "    fv = set(feature_vector)\n",
      "    # maps each  most-frequent term to an offset in feature vector\n",
      "    term_vector_lut = { t:i for i, t in enumerate(fv) }\n",
      "    # remove all words from each line not in the feature_vector\n",
      "    d = (filter(lambda q: q in fv, line) for line in data)\n",
      "    d = deepcopy([list(line) for line in d])\n",
      "    # initialize the empty 2D NumPy array returned \n",
      "    m, n = len(d), len(term_vector_lut)\n",
      "    D = NP.zeros((m, n))\n",
      "    dx = CL.defaultdict(int)\n",
      "    c = 0\n",
      "    for line in d:\n",
      "        new_row = NP.zeros(len(fv))\n",
      "        for w in line:\n",
      "            idx = term_vector_lut[w]\n",
      "            new_row[idx] += 1\n",
      "        D[c,:] = new_row\n",
      "        c += 1\n",
      "    return D"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v1 = [t[1] for t in term_count_1_sorted[:50]]\n",
      "v0 = [t[1] for t in term_count_0_sorted[:50]]\n",
      "\n",
      "v1.extend(v0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = build_feature_vector(d, v1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import warnings\n",
      "warnings.filterwarnings('ignore', r\"object.__format__ with a non-empty format string is deprecated\")\n",
      "                        \n",
      "a1 = [ (w, c) for c, w in term_count_1_sorted[:50] ]\n",
      "a0 = [ (w, c) for c, w in term_count_0_sorted[:50] ]\n",
      "a10 = zip(a1, a0)\n",
      "H1 = '{0} most frequent terms by class'.format(len(a1))\n",
      "H1 = \"50 most frequent terms in each class\"\n",
      "h2a = 'class I'\n",
      "h2b = 'class 0'\n",
      "ula, ulb = 15 * '_', 15 * '_'\n",
      "print(\"{0:^50}\\n\".format(H1))\n",
      "print(\"{0:^20}\\t{1:^30}\".format(h2a, h2b))\n",
      "print(\"{0:30}\\t{1:35}\".format(ula, ulb))\n",
      "#for i, o in a10:\n",
      "# print(\"{0:25}\\t{1}\".format(i, o))\n",
      "for i, o in a10:\n",
      "    print(\"{0:25}\\t{1:35}\".format(i, o))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       50 most frequent terms in each class       \n",
        "\n",
        "      class I       \t           class 0            \n",
        "_______________               \t_______________                    \n",
        "('workout', 2292)        \t('player', 491)                    \n",
        "('exercise', 1810)       \t('world', 424)                     \n",
        "('training', 1105)       \t('level', 424)                     \n",
        "('fitnes', 1050)         \t('game', 405)                      \n",
        "('weight', 962)          \t('friend', 385)                    \n",
        "('muscle', 697)          \t('score', 380)                     \n",
        "('track', 667)           \t('wallpaper', 332)                 \n",
        "('calorie', 567)         \t('bible', 313)                     \n",
        "('health', 534)          \t('track', 281)                     \n",
        "('program', 530)         \t('sport', 280)                     \n",
        "('daily', 481)           \t('church', 279)                    \n",
        "('timer', 438)           \t('acces', 268)                     \n",
        "('level', 356)           \t('support', 264)                   \n",
        "('routine', 355)         \t('search', 255)                    \n",
        "('trainer', 343)         \t('point', 247)                     \n",
        "('running', 337)         \t('photo', 246)                     \n",
        "('personal', 331)        \t('football', 243)                  \n",
        "('distance', 317)        \t('right', 238)                     \n",
        "('heart', 313)           \t('music', 236)                     \n",
        "('minute', 311)          \t('favorite', 231)                  \n",
        "('support', 303)         \t('update', 215)                    \n",
        "('result', 297)          \t('league', 198)                    \n",
        "('progres', 296)         \t('speed', 197)                     \n",
        "('allow', 289)           \t('including', 197)                 \n",
        "('sport', 280)           \t('number', 195)                    \n",
        "('start', 275)           \t('puzzle', 194)                    \n",
        "('music', 275)           \t('enjoy', 194)                     \n",
        "('record', 272)          \t('learn', 191)                     \n",
        "('strength', 258)        \t('control', 191)                   \n",
        "('create', 257)          \t('online', 188)                    \n",
        "('friend', 249)          \t('experience', 187)                \n",
        "('healthy', 246)         \t('image', 185)                     \n",
        "('people', 235)          \t('start', 181)                     \n",
        "('speed', 226)           \t('picture', 180)                   \n",
        "('interval', 225)        \t('location', 180)                  \n",
        "('building', 225)        \t('prayer', 178)                    \n",
        "('improve', 212)         \t('google', 177)                    \n",
        "('acces', 209)           \t('weight', 175)                    \n",
        "('sleep', 208)           \t('audio', 175)                     \n",
        "('learn', 206)           \t('power', 171)                     \n",
        "('change', 206)          \t('latest', 169)                    \n",
        "('calculator', 205)      \t('system', 166)                    \n",
        "('designed', 199)        \t('challenge', 156)                 \n",
        "('based', 192)           \t('calendar', 156)                  \n",
        "('activity', 191)        \t('result', 154)                    \n",
        "('tracking', 188)        \t('around', 154)                    \n",
        "('session', 188)         \t('unique', 152)                    \n",
        "('video', 187)           \t('include', 152)                   \n",
        "('without', 184)         \t('check', 152)                     \n",
        "('system', 184)          \t('change', 152)                    \n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# shuffle the data\n",
      "L = L.reshape(-1, 1)\n",
      "DL = NP.hstack((D, L))\n",
      "idx = NP.random.permutation(NP.arange(D.shape[0]))\n",
      "DL = DL[idx,]\n",
      "\n",
      "D, L = NP.hsplit(DL, [-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "optimization I: add features comprised of frequently occurring _pairs_ of words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get pairwise frequencies for most common terms\n",
      "\n",
      "t1 = [ t for cn, t in term_count_1_sorted[:25] ]\n",
      "t0 = [ t for cn, t in term_count_0_sorted[:25] ]\n",
      "\n",
      "fv = set(v1)\n",
      "\n",
      "tv_lut = { t:i for i, t in enumerate(fv) }\n",
      "\n",
      "LuT = tv_lut\n",
      "LuT_r = { i:t for i, t in enumerate(fv) }\n",
      "\n",
      "# indices for 50 most frequent terms in class I instances\n",
      "idx_ft1 = [ LuT[term] for term in t1 ]\n",
      "idx_ft0 = [ LuT[term] for term in t0 ]\n",
      "\n",
      "D, L = NP.hsplit(DL, [-1])\n",
      "L = L.squeeze()\n",
      "\n",
      "D = NP.where(D>0, 1, 0)\n",
      "D = NP.array(D, dtype=bool)\n",
      "\n",
      "idx1 = L==1\n",
      "idx0 = L==0\n",
      "\n",
      "# class I instances\n",
      "D1 = D[idx1,]\n",
      "\n",
      "#class 0 instances\n",
      "D0 = D[idx0,]\n",
      "\n",
      "# now select just those columns that represent a top 20 term\n",
      "DT1 = D1.T[idx_ft1,]\n",
      "DT0 = D0.T[idx_ft0,]\n",
      "\n",
      "# remap offsets in new arrays (DT1, DT2) to the offsets for the complete dataset\n",
      "lut_ft1, lut_ft0 = dict(enumerate(idx_ft1)), dict(enumerate(idx_ft0))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools as IT\n",
      "\n",
      "def cofreq_score(v1, v2):\n",
      "    \"\"\"\n",
      "    returns: scalar that represents co-occurrence frequency\n",
      "    pass in: 2 x 1D NumPy arrays of dtype 'bool'\n",
      "    \"\"\"\n",
      "    return NP.sum(v1 & v2)\n",
      "\n",
      "\n",
      "def prep(t, D=DT1):\n",
      "    \"\"\"\n",
      "    returns: v1, v2 to pass to cofreq_score\n",
      "    pass in: \n",
      "        (i) a tuple of offsets;\n",
      "        (ii) a transposed dataset as a 2D NumPy array\n",
      "    \"\"\"\n",
      "    idx_v1, idx_v2 = t\n",
      "    return D[idx_v1], D[idx_v2]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_pair_offsets = IT.combinations(range(DT1.shape[0]), 2)\n",
      "\n",
      "C = [ ( cofreq_score(*prep(t)), t )  for i, t in enumerate(term_pair_offsets) ]\n",
      "\n",
      "C = sorted(list(C), reverse=True)\n",
      "for score, t in C:\n",
      "    print(\"{0}\\t{1}\".format(score, t))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "327\t(0, 1)\n",
        "244\t(0, 3)\n",
        "229\t(1, 3)\n",
        "214\t(0, 2)\n",
        "210\t(1, 4)\n",
        "208\t(1, 5)\n",
        "205\t(1, 2)\n",
        "176\t(0, 4)\n",
        "175\t(0, 5)\n",
        "172\t(1, 8)\n",
        "170\t(2, 3)\n",
        "156\t(3, 8)\n",
        "155\t(0, 6)\n",
        "152\t(3, 4)\n",
        "140\t(0, 16)\n",
        "135\t(4, 6)\n",
        "134\t(6, 22)\n",
        "133\t(1, 16)\n",
        "132\t(1, 9)\n",
        "128\t(1, 14)\n",
        "128\t(0, 14)\n",
        "127\t(14, 16)\n",
        "127\t(4, 7)\n",
        "126\t(0, 22)\n",
        "125\t(1, 12)\n",
        "124\t(1, 13)\n",
        "124\t(1, 6)\n",
        "123\t(3, 5)\n",
        "122\t(1, 10)\n",
        "122\t(0, 9)\n",
        "120\t(3, 16)\n",
        "120\t(0, 12)\n",
        "119\t(3, 12)\n",
        "118\t(0, 13)\n",
        "117\t(3, 6)\n",
        "116\t(1, 19)\n",
        "112\t(2, 4)\n",
        "109\t(4, 5)\n",
        "109\t(0, 8)\n",
        "108\t(1, 21)\n",
        "105\t(4, 8)\n",
        "105\t(0, 20)\n",
        "104\t(2, 6)\n",
        "104\t(1, 22)\n",
        "104\t(0, 23)\n",
        "103\t(6, 7)\n",
        "101\t(6, 17)\n",
        "101\t(3, 14)\n",
        "101\t(1, 20)\n",
        "99\t(3, 9)\n",
        "97\t(2, 5)\n",
        "96\t(0, 17)\n",
        "96\t(0, 11)\n",
        "95\t(2, 14)\n",
        "95\t(1, 23)\n",
        "95\t(1, 11)\n",
        "95\t(0, 15)\n",
        "94\t(3, 22)\n",
        "92\t(8, 10)\n",
        "92\t(3, 7)\n",
        "92\t(2, 9)\n",
        "92\t(0, 19)\n",
        "91\t(2, 16)\n",
        "91\t(0, 7)\n",
        "90\t(0, 10)\n",
        "88\t(4, 16)\n",
        "88\t(2, 24)\n",
        "88\t(0, 21)\n",
        "86\t(4, 22)\n",
        "84\t(6, 23)\n",
        "84\t(4, 10)\n",
        "84\t(2, 22)\n",
        "84\t(1, 7)\n",
        "82\t(2, 15)\n",
        "82\t(2, 12)\n",
        "81\t(7, 17)\n",
        "81\t(6, 20)\n",
        "81\t(4, 9)\n",
        "79\t(8, 12)\n",
        "79\t(6, 15)\n",
        "78\t(15, 17)\n",
        "78\t(6, 16)\n",
        "78\t(3, 21)\n",
        "76\t(4, 12)\n",
        "76\t(3, 24)\n",
        "76\t(2, 20)\n",
        "76\t(1, 24)\n",
        "75\t(2, 8)\n",
        "74\t(5, 8)\n",
        "73\t(4, 23)\n",
        "73\t(3, 20)\n",
        "72\t(4, 20)\n",
        "72\t(2, 21)\n",
        "71\t(8, 16)\n",
        "71\t(6, 8)\n",
        "71\t(5, 13)\n",
        "70\t(2, 23)\n",
        "70\t(2, 17)\n",
        "69\t(4, 21)\n",
        "69\t(3, 15)\n",
        "68\t(3, 19)\n",
        "68\t(3, 13)\n",
        "68\t(0, 24)\n",
        "67\t(3, 17)\n",
        "66\t(8, 20)\n",
        "66\t(3, 10)\n",
        "65\t(7, 10)\n",
        "65\t(5, 12)\n",
        "65\t(5, 9)\n",
        "64\t(1, 15)\n",
        "63\t(6, 10)\n",
        "63\t(4, 13)\n",
        "63\t(3, 23)\n",
        "61\t(6, 12)\n",
        "61\t(5, 14)\n",
        "61\t(2, 11)\n",
        "60\t(10, 16)\n",
        "60\t(7, 15)\n",
        "60\t(7, 8)\n",
        "59\t(2, 7)\n",
        "58\t(17, 22)\n",
        "58\t(16, 23)\n",
        "58\t(15, 22)\n",
        "58\t(6, 9)\n",
        "58\t(2, 19)\n",
        "56\t(12, 16)\n",
        "56\t(7, 22)\n",
        "56\t(5, 19)\n",
        "56\t(5, 16)\n",
        "56\t(4, 15)\n",
        "56\t(2, 13)\n",
        "55\t(4, 14)\n",
        "54\t(22, 23)\n",
        "54\t(16, 22)\n",
        "54\t(2, 18)\n",
        "54\t(1, 18)\n",
        "54\t(0, 18)\n",
        "53\t(12, 21)\n",
        "53\t(9, 12)\n",
        "53\t(7, 12)\n",
        "52\t(17, 23)\n",
        "52\t(17, 20)\n",
        "52\t(7, 16)\n",
        "51\t(20, 22)\n",
        "51\t(9, 16)\n",
        "51\t(8, 9)\n",
        "51\t(6, 21)\n",
        "50\t(12, 23)\n",
        "50\t(10, 19)\n",
        "50\t(9, 22)\n",
        "49\t(3, 18)\n",
        "48\t(10, 12)\n",
        "48\t(4, 17)\n",
        "47\t(15, 20)\n",
        "47\t(13, 14)\n",
        "47\t(12, 19)\n",
        "47\t(6, 24)\n",
        "47\t(5, 10)\n",
        "46\t(15, 23)\n",
        "46\t(13, 16)\n",
        "46\t(12, 20)\n",
        "46\t(12, 14)\n",
        "46\t(8, 23)\n",
        "46\t(8, 18)\n",
        "46\t(6, 18)\n",
        "46\t(1, 17)\n",
        "45\t(10, 23)\n",
        "44\t(16, 20)\n",
        "44\t(9, 14)\n",
        "44\t(8, 24)\n",
        "44\t(8, 14)\n",
        "44\t(7, 23)\n",
        "44\t(5, 20)\n",
        "44\t(4, 19)\n",
        "44\t(4, 18)\n",
        "43\t(9, 13)\n",
        "43\t(8, 19)\n",
        "43\t(4, 24)\n",
        "43\t(2, 10)\n",
        "42\t(18, 20)\n",
        "42\t(12, 22)\n",
        "42\t(9, 19)\n",
        "42\t(8, 22)\n",
        "42\t(8, 21)\n",
        "42\t(5, 21)\n",
        "41\t(19, 23)\n",
        "41\t(10, 20)\n",
        "41\t(9, 21)\n",
        "41\t(7, 20)\n",
        "40\t(16, 21)\n",
        "40\t(14, 23)\n",
        "40\t(11, 19)\n",
        "40\t(9, 15)\n",
        "40\t(3, 11)\n",
        "39\t(21, 22)\n",
        "39\t(19, 24)\n",
        "39\t(19, 21)\n",
        "39\t(17, 18)\n",
        "39\t(14, 21)\n",
        "39\t(12, 17)\n",
        "39\t(10, 13)\n",
        "39\t(9, 20)\n",
        "39\t(9, 10)\n",
        "39\t(7, 18)\n",
        "39\t(5, 11)\n",
        "38\t(16, 24)\n",
        "38\t(15, 24)\n",
        "38\t(15, 16)\n",
        "38\t(14, 19)\n",
        "38\t(11, 16)\n",
        "38\t(10, 14)\n",
        "38\t(5, 23)\n",
        "37\t(21, 23)\n",
        "37\t(6, 19)\n",
        "37\t(5, 22)\n",
        "37\t(5, 6)\n",
        "36\t(13, 23)\n",
        "36\t(11, 23)\n",
        "36\t(11, 12)\n",
        "36\t(9, 23)\n",
        "35\t(19, 20)\n",
        "35\t(14, 24)\n",
        "35\t(13, 19)\n",
        "35\t(12, 24)\n",
        "35\t(11, 14)\n",
        "35\t(7, 21)\n",
        "35\t(6, 14)\n",
        "35\t(6, 13)\n",
        "34\t(20, 21)\n",
        "34\t(16, 19)\n",
        "34\t(16, 17)\n",
        "34\t(11, 22)\n",
        "33\t(20, 23)\n",
        "33\t(18, 22)\n",
        "33\t(14, 22)\n",
        "33\t(12, 15)\n",
        "33\t(7, 19)\n",
        "33\t(4, 11)\n",
        "32\t(15, 19)\n",
        "32\t(10, 22)\n",
        "32\t(8, 17)\n",
        "32\t(7, 9)\n",
        "32\t(5, 24)\n",
        "31\t(22, 24)\n",
        "31\t(17, 24)\n",
        "31\t(13, 22)\n",
        "31\t(10, 24)\n",
        "31\t(7, 24)\n",
        "30\t(14, 15)\n",
        "30\t(12, 13)\n",
        "30\t(10, 21)\n",
        "30\t(9, 24)\n",
        "29\t(21, 24)\n",
        "29\t(12, 18)\n",
        "29\t(11, 13)\n",
        "29\t(9, 17)\n",
        "28\t(19, 22)\n",
        "28\t(16, 18)\n",
        "28\t(15, 18)\n",
        "27\t(17, 19)\n",
        "27\t(15, 21)\n",
        "27\t(6, 11)\n",
        "26\t(23, 24)\n",
        "26\t(13, 21)\n",
        "26\t(11, 15)\n",
        "26\t(10, 17)\n",
        "26\t(8, 15)\n",
        "26\t(8, 13)\n",
        "26\t(7, 14)\n",
        "25\t(20, 24)\n",
        "25\t(18, 23)\n",
        "25\t(5, 7)\n",
        "24\t(18, 24)\n",
        "24\t(11, 20)\n",
        "24\t(5, 18)\n",
        "23\t(13, 24)\n",
        "23\t(9, 11)\n",
        "22\t(11, 24)\n",
        "21\t(5, 15)\n",
        "19\t(13, 20)\n",
        "19\t(10, 11)\n",
        "18\t(14, 20)\n",
        "18\t(14, 17)\n",
        "18\t(10, 15)\n",
        "17\t(18, 21)\n",
        "17\t(14, 18)\n",
        "17\t(13, 15)\n",
        "16\t(18, 19)\n",
        "16\t(17, 21)\n",
        "16\t(11, 21)\n",
        "15\t(9, 18)\n",
        "15\t(8, 11)\n",
        "13\t(10, 18)\n",
        "13\t(7, 13)\n",
        "12\t(11, 17)\n",
        "10\t(13, 18)\n",
        "9\t(7, 11)\n",
        "8\t(13, 17)\n",
        "8\t(5, 17)\n",
        "7\t(11, 18)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "optimization II: improve classifier accuracy by applying a weight vector to each feature vector"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_count_1 = term_counter(words_1)\n",
      "term_count_0 = term_counter(words_0)\n",
      "term_count_all = term_counter(words_01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_top_20_class1 = a1[:20]\n",
      "term_top_20_class0 = a0[:20]\n",
      "\n",
      "# constructing the weight vector:\n",
      "\n",
      "for t in term_top_20_class1:\n",
      "    print(\"term: {0}\\t weight: {1:.2f}\".format(t[0], t[1]/term_count_0[t[0]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "term: workout\t weight: 76.40\n",
        "term: exercise\t weight: 29.67\n",
        "term: training\t weight: 14.93\n",
        "term: fitnes\t weight: 33.87\n",
        "term: weight\t weight: 5.50\n",
        "term: muscle\t weight: 174.25\n",
        "term: track\t weight: 2.37\n",
        "term: calorie\t weight: 13.50\n",
        "term: health\t weight: 9.54\n",
        "term: program\t weight: 10.19\n",
        "term: daily\t weight: 4.22\n",
        "term: timer\t weight: 10.19\n",
        "term: level\t weight: 0.84\n",
        "term: routine\t weight: 32.27\n",
        "term: trainer\t weight: 24.50\n",
        "term: running\t weight: 5.35\n",
        "term: personal\t weight: 5.17\n",
        "term: distance\t weight: 3.64\n",
        "term: heart\t weight: 5.69\n",
        "term: minute\t weight: 5.36\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the other portion of the weight vector:\n",
      "\n",
      "for t in term_top_20_class0:\n",
      "    print(\"term: {0}\\t weight: {1:.2f}\".format(t[0], t[1]/(term_count_1[t[0]]+1)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "term: player\t weight: 10.45\n",
        "term: world\t weight: 2.99\n",
        "term: level\t weight: 1.19\n",
        "term: game\t weight: 18.41\n",
        "term: friend\t weight: 1.54\n",
        "term: score\t weight: 6.44\n",
        "term: wallpaper\t weight: 9.76\n",
        "term: bible\t weight: 156.50\n",
        "term: track\t weight: 0.42\n",
        "term: sport\t weight: 1.00\n",
        "term: church\t weight: 279.00\n",
        "term: acces\t weight: 1.28\n",
        "term: support\t weight: 0.87\n",
        "term: search\t weight: 1.72\n",
        "term: point\t weight: 1.58\n",
        "term: photo\t weight: 2.26\n",
        "term: football\t weight: 40.50\n",
        "term: right\t weight: 1.52\n",
        "term: music\t weight: 0.86\n",
        "term: favorite\t weight: 1.96\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words_1 = [ word for line in d1 for word in line ]\n",
      "words_0 = [ word for line in d0 for word in line ]\n",
      "words_01 = [ word for line in d for word in line ]\n",
      "\n",
      "a1 = [ (w, c) for c, w in term_count_1_sorted[:20] ]\n",
      "a0 = [ (w, c) for c, w in term_count_0_sorted[:20] ]\n",
      "\n",
      "a10 = zip(a1, a0)\n",
      "H1 = '{0} most frequent terms by class'.format(len(a1))\n",
      "H1 = \"50 most frequent terms in each class\"\n",
      "h2a = 'class I'\n",
      "h2b = 'class 0'\n",
      "ula, ulb = 15 * '_', 15 * '_'\n",
      "print(\"{0:^50}\\n\".format(H1))\n",
      "print(\"{0:^20}\\t{1:^30}\".format(h2a, h2b))\n",
      "print(\"{0:30}\\t{1:35}\".format(ula, ulb))\n",
      "#for i, o in a10:\n",
      "# print(\"{0:25}\\t{1}\".format(i, o))\n",
      "for i, o in a10:\n",
      "    print(\"{0:25}\\t{1:35}\".format(i, o))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       50 most frequent terms in each class       \n",
        "\n",
        "      class I       \t           class 0            \n",
        "_______________               \t_______________                    \n",
        "('workout', 2292)        \t('player', 491)                    \n",
        "('exercise', 1810)       \t('world', 424)                     \n",
        "('training', 1105)       \t('level', 424)                     \n",
        "('fitnes', 1050)         \t('game', 405)                      \n",
        "('weight', 962)          \t('friend', 385)                    \n",
        "('muscle', 697)          \t('score', 380)                     \n",
        "('track', 667)           \t('wallpaper', 332)                 \n",
        "('calorie', 567)         \t('bible', 313)                     \n",
        "('health', 534)          \t('track', 281)                     \n",
        "('program', 530)         \t('sport', 280)                     \n",
        "('daily', 481)           \t('church', 279)                    \n",
        "('timer', 438)           \t('acces', 268)                     \n",
        "('level', 356)           \t('support', 264)                   \n",
        "('routine', 355)         \t('search', 255)                    \n",
        "('trainer', 343)         \t('point', 247)                     \n",
        "('running', 337)         \t('photo', 246)                     \n",
        "('personal', 331)        \t('football', 243)                  \n",
        "('distance', 317)        \t('right', 238)                     \n",
        "('heart', 313)           \t('music', 236)                     \n",
        "('minute', 311)          \t('favorite', 231)                  \n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def partition_data(data, class_labels, train_test_ratio=.9):\n",
      "    \"\"\"\n",
      "    returns: data & class labels, split into training and test groups,\n",
      "        as 2 x 2-tuples; \n",
      "        these 2 containers are suitable to pass to scikit-learn classifier\n",
      "        objects\n",
      "        to call their 'fit' method, pass in *tr; \n",
      "        for 'predict', pass in te[0];\n",
      "        for 'score' pass in *te\n",
      "    pass in: \n",
      "        data, 2D NumPy array\n",
      "        class labels, 1D NumPy array\n",
      "        train:test ratio: 0 < f < 1, default is 0.9\n",
      "    bind the result returned from call to this fn to two variables, \n",
      "        like so: tr, te = partition_data()\n",
      "        each variable represents a tuple comprised of data + labels\n",
      "    \"\"\"\n",
      "    # create a vector that holds the row indices\n",
      "    NP.random.seed(0)\n",
      "    idx = NP.random.permutation(data.shape[0])\n",
      "    # now order both data and class labels arrays by idx\n",
      "    D = data[idx,]\n",
      "    L = class_labels[idx]\n",
      "    # allocate the data to test & train partitions according to\n",
      "    # the train_test_ratio passed in\n",
      "    q = int(NP.ceil(train_test_ratio * D.shape[0]))\n",
      "    D_tr = D[:q,:]\n",
      "    D_te = D[q:,:]\n",
      "    L_tr = L[:q]\n",
      "    L_te = L[q:]\n",
      "    assert D_tr.shape[0] + D_te.shape[0] == D.shape[0]\n",
      "    assert L_tr.shape[0] + L_te.shape[0] == L.shape[0]\n",
      "    # 1D array required by scikit-learn\n",
      "    L_tr, L_te = NP.squeeze(L_tr), NP.squeeze(L_te)\n",
      "    return (D_tr, L_tr), (D_te, L_te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# partition the data into training & test sets\n",
      "# tr, te = partition_data(D, L)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn import datasets\n",
      "# iris = datasets.load_iris()\n",
      "# data = iris.data\n",
      "# labels = iris.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import the scikit-learn library that includes the three main Naive Bayes classifier factories\n",
      "from sklearn import naive_bayes as NB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tr, te = partition_data(D, L)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# instantiate a Gaussian Naive Bayesian classifier\n",
      "# gnb = NB.GaussianNB()\n",
      "mnb = NB.MultinomialNB(alpha=0.01, fit_prior=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb.fit(*tr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=False)"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnb_pred = mnb.predict(te[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"{0:.2f}\".format(mnb.score(*te)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.91\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}